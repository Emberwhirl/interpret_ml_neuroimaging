{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN and LRP on Social Physical brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how saliency maps are computed for social and physical pain brain dataset. \n",
    "\n",
    "We will first train a model and then apply LRP methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import h5py\n",
    "import imp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "import keras.models\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "# Use utility libraries to focus on relevant iNNvestigate routines.\n",
    "eutils = imp.load_source(\"utils\", \"utils_lrp.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable\n",
    "Set the variable for making model and the analysis.\n",
    "\n",
    "Before running, unzip 'mini_example_social_physical_masked_cross.hdf5' in data folder. \n",
    "\n",
    "* mini_batch_size : batch size you want to run\n",
    "* data_file_name : where your data exist\n",
    "* label_to_class_name : put labels in the list\n",
    "* selection_index_LRP : which index do you want the LRP results with? 1 is for Social score and 0 is for Physical score and None is for the most model prediction score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size = 128\n",
    "data_file_name = 'data/mini_example_social_physical_masked_cross.hdf5'\n",
    "label_to_class_name = [str(i) for i in range(2)]\n",
    "selection_index_LRP = 0 # 0, 1, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "This part is for training and evaluating CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make CNN model with 6 layers, Flatten() is inserted between CNN and fully connected layers.\n",
    "def make_custom_model_cnn_2D():\n",
    "    \n",
    "    model = Sequential() \n",
    "    model.add(Conv2D(8, (3,3), kernel_initializer='he_normal', padding='same', input_shape=(68,95,79)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(16, (3,3), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), kernel_initializer='he_normal', padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(128, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(2, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('linear'))\n",
    "    \n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for creating & training model\n",
    "def train_model():\n",
    "\n",
    "    # Option : when you have enough GPUs, it will be better to cancle the annotation of below line \n",
    "#     with tf.device('/cpu:0'):\n",
    "\n",
    "    with h5py.File(data_file_name, \"r\") as data:\n",
    "\n",
    "        for i in range(0,3):  # i is the cross number 59\n",
    "\n",
    "            print('this is ith iter : ' , i)\n",
    "\n",
    "            tr_data_X_name = 'cross_'+str(i+1)+ '_X'+'_train'\n",
    "            tr_data_y_name = 'cross_'+str(i+1)+ '_y'+'_train'\n",
    "            te_data_X_name = 'cross_'+str(i+1)+ '_X'+'_test'\n",
    "            te_data_y_name = 'cross_'+str(i+1)+ '_y'+'_test'\n",
    "\n",
    "            tr_data = {}\n",
    "            tr_data['X_data'] = np.array(data[tr_data_X_name])\n",
    "            tr_data['y_data'] = np.array(data[tr_data_y_name])\n",
    "            \n",
    "            te_data = {}\n",
    "            te_data['X_data'] = np.array(data[te_data_X_name])\n",
    "            te_data['y_data'] = np.array(data[te_data_y_name])\n",
    "            \n",
    "            tr_data['y_data'] = keras.utils.to_categorical(tr_data['y_data'], 2)\n",
    "            te_data['y_data'] = keras.utils.to_categorical(te_data['y_data'], 2)\n",
    "   \n",
    "            training_sample_count = tr_data['X_data'].shape[0]\n",
    "\n",
    "\n",
    "            # Initialize and compile the model\n",
    "            model = make_custom_model_cnn_2D()\n",
    "            model.compile(loss=\"categorical_crossentropy\",\n",
    "                          optimizer=Adam(),\n",
    "                          metrics=[\"accuracy\"])\n",
    "            history = model.fit(tr_data['X_data'],\n",
    "                                tr_data['y_data'],\n",
    "                                batch_size=mini_batch_size,\n",
    "                                epochs=20,\n",
    "                                verbose=1)\n",
    "            score = model.evaluate(te_data['X_data'], \n",
    "                                   te_data['y_data'], \n",
    "                                   verbose=0)\n",
    "            return model,score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is ith iter :  0\n",
      "Epoch 1/20\n",
      "928/928 [==============================] - 5s 6ms/step - loss: 1.1083 - acc: 0.5399\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 5s 5ms/step - loss: 0.6548 - acc: 0.6584\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 5s 6ms/step - loss: 0.5452 - acc: 0.7511\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 4s 4ms/step - loss: 0.4719 - acc: 0.8103\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 5s 5ms/step - loss: 0.3781 - acc: 0.8481\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 5s 5ms/step - loss: 0.3314 - acc: 0.8707\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 4s 5ms/step - loss: 0.3049 - acc: 0.8836\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 5s 5ms/step - loss: 0.2407 - acc: 0.9106\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 5s 5ms/step - loss: 0.1995 - acc: 0.9278\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 5s 5ms/step - loss: 0.1609 - acc: 0.9494\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 5s 5ms/step - loss: 0.1286 - acc: 0.9601\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 4s 5ms/step - loss: 0.1104 - acc: 0.9666\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 5s 5ms/step - loss: 0.0942 - acc: 0.9752\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 5s 5ms/step - loss: 0.0687 - acc: 0.9817\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 5s 5ms/step - loss: 0.0526 - acc: 0.9881\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 5s 5ms/step - loss: 0.0422 - acc: 0.9925\n",
      "Epoch 17/20\n",
      "928/928 [==============================] - 4s 5ms/step - loss: 0.0336 - acc: 0.9957\n",
      "Epoch 18/20\n",
      "928/928 [==============================] - 4s 4ms/step - loss: 0.0265 - acc: 0.9989\n",
      "Epoch 19/20\n",
      "928/928 [==============================] - 4s 4ms/step - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "928/928 [==============================] - 4s 4ms/step - loss: 0.0136 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Create & train model\n",
    "model,score = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for  0  th iter :  1.0\n",
      "mean of validation accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "#List for save accuracy\n",
    "val_acc = [] \n",
    "\n",
    "\n",
    "with h5py.File(data_file_name, \"r\") as data:\n",
    "\n",
    "    for i in range(0,1):  # i is the cross number 59\n",
    "\n",
    "        te_data_X_name = 'cross_'+str(i+1)+ '_X'+'_test'\n",
    "        te_data_y_name = 'cross_'+str(i+1)+ '_y'+'_test'\n",
    "\n",
    "        te_data = {}\n",
    "        te_data['X_data'] = np.array(data[te_data_X_name])\n",
    "        te_data['y_data'] = np.array(data[te_data_y_name])\n",
    "        \n",
    "        te_data['y_data'] = keras.utils.to_categorical(te_data['y_data'], 2)\n",
    "        \n",
    "\n",
    "        score = model.evaluate(te_data['X_data'], te_data['y_data'], verbose=0)\n",
    "        val_acc.append(score[1])\n",
    "        \n",
    "        print(\"accuracy for \", i, \" th iter : \",score[1])\n",
    "\n",
    "print(\"mean of validation accuracy : \",np.mean(val_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a list of analysis methods used by `innvestigate.analyzer.create_analyzer(...)`, some optional parameters, a post processing choice for visualizing the computed analysis and a title for the figure to render. \n",
    "\n",
    "\n",
    "For a full list of methods refer to the dictionary `investigate.analyzer.analyzers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure analysis methods and properties\n",
    "if selection_index_LRP == None:\n",
    "    methods = [\n",
    "    (\"lrp.epsilon\",    {\"epsilon\": 1,\"neuron_selection_mode\":\"max_activation\"},    ivis.heatmap,    \"LRP-Epsilon\"),\n",
    "    ]\n",
    "else:    \n",
    "    methods = [\n",
    "    (\"lrp.epsilon\",    {\"epsilon\": 1, \"neuron_selection_mode\" : \"index\"},    ivis.heatmap,     \"LRP-Epsilon\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main loop below will now instantiate the analyzer objects based on the loaded/trained model and the analyzers' parameterizations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model without trailing softmax\n",
    "model_wo_softmax = iutils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "# Create analyzers.\n",
    "analyzers = []\n",
    "for method in methods:\n",
    "    \n",
    "    analyzer = innvestigate.create_analyzer(method[0],        # analysis method identifier\n",
    "                                            model_wo_softmax, # model without softmax output\n",
    "                                            **method[1])      # optional analysis parameters\n",
    "\n",
    "    # Some analyzers require training.\n",
    "    analyzer.fit(data, batch_size=256, verbose=1)\n",
    "    analyzers.append(analyzer)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we analyze each image with the different analyzers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is ith iter :  0\n",
      "('ground truth label : 0', 'predicted label : 0')\n",
      "\n",
      "('ground truth label : 0', 'predicted label : 0')\n",
      "\n",
      "('ground truth label : 0', 'predicted label : 0')\n",
      "\n",
      "('ground truth label : 0', 'predicted label : 0')\n",
      "\n",
      "('ground truth label : 0', 'predicted label : 0')\n",
      "\n",
      "('ground truth label : 0', 'predicted label : 0')\n",
      "\n",
      "('ground truth label : 0', 'predicted label : 0')\n",
      "\n",
      "('ground truth label : 0', 'predicted label : 0')\n",
      "\n",
      "('ground truth label : 1', 'predicted label : 1')\n",
      "\n",
      "('ground truth label : 1', 'predicted label : 1')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "\n",
    "with h5py.File(data_file_name, \"r\") as data:\n",
    "\n",
    "    for i in range(0,1):  # i is the cross number 59\n",
    "\n",
    "        tr_data_X_name = 'cross_'+str(i+1)+ '_X'+'_test'\n",
    "        tr_data_y_name = 'cross_'+str(i+1)+ '_y'+'_test'\n",
    "\n",
    "        tr_data = {}\n",
    "        tr_data['X_data'] = np.array(data[tr_data_X_name])\n",
    "        tr_data['y_data'] = np.array(data[tr_data_y_name])\n",
    "        \n",
    "        test_data = tr_data['X_data']\n",
    "        test_label = tr_data['y_data']\n",
    "\n",
    "        n = 10\n",
    "        test_images = list(zip(test_data[:n], test_label[:n]))\n",
    "\n",
    "        analysis = np.zeros([len(test_images), len(analyzers), 68, 95, 3])\n",
    "        text = []\n",
    "        R=[]\n",
    "\n",
    "\n",
    "\n",
    "        for p, (x, y) in enumerate(test_images):\n",
    "            # Add batch axis.\n",
    "            x = x[None, :, :, :]\n",
    "\n",
    "            # Predict final activations, probabilites, and label.\n",
    "            presm = model_wo_softmax.predict_on_batch(x)[0]\n",
    "            prob = model.predict_on_batch(x)[0]\n",
    "            y_hat = prob.argmax()\n",
    "\n",
    "\n",
    "            # Save prediction info:\n",
    "            text.append((\"ground truth label : %s\" % label_to_class_name[int(y)],    # ground truth label\n",
    "                         \n",
    "                         \"predicted label : %s\" % label_to_class_name[y_hat]         # predicted label\n",
    "                        ))\n",
    "\n",
    "            for aidx, analyzer in enumerate(analyzers):\n",
    "                # Analyze.\n",
    "                if selection_index_LRP == None:\n",
    "                    a = analyzer.analyze(x)\n",
    "                else:\n",
    "                    a = analyzer.analyze(x, neuron_selection=selection_index_LRP)\n",
    "                \n",
    "                # Save natual R\n",
    "                R.append(a) \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        # Save Relevance as numpy\n",
    "        R_name = 'social_physical_brain_relevance_cross_'+str(i)+'.npy'\n",
    "        np.save(R_name, R)\n",
    "\n",
    "        print('this is ith iter : ' , i)\n",
    "        \n",
    "        for i in range(len(text)):\n",
    "            \n",
    "            print(text[i])\n",
    "            print()\n",
    "        \n",
    "        \n",
    "        \n",
    "#         \"pre-softmax logits : %.2f\" % presm.max(),                  # pre-softmax logits\n",
    "#         \"probabilistic softmax output   : %.2f\" % prob.max(),       # probabilistic softmax output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See one example of Relevance of Brain.\n",
    "\n",
    "For precise visualization, please refer the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose one person and one dimension\n",
    "R_ = np.load('social_physical_brain_relevance_cross_0.npy')[8]\n",
    "R_ = R_.reshape(68,95,79)\n",
    "\n",
    "R_ = R_[:,30]\n",
    "\n",
    "plt.imshow(R_, cmap=plt.cm.seismic, interpolation='nearest') #, interpolation='nearest'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
